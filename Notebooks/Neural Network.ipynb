{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from Preprocessing import preprocessing\n",
    "from Preprocessing.single_set import SingleSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Features: data.data_features\n",
    "Targets: data.data_targets (click, bidprice, payprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- data loaded --\n",
      "-- data loaded --\n"
     ]
    }
   ],
   "source": [
    "train_data_path = '/Data/train.csv'\n",
    "train_data = SingleSet(relative_path=data_path,use_numerical_labels=True)\n",
    "\n",
    "val_data_path = '/Data/validation.csv'\n",
    "val_data = SingleSet(relative_path=data_path,use_numerical_labels=True)\n",
    "\n",
    "## potentially drop unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_classification(data):\n",
    "\n",
    "    ## features\n",
    "    features = np.asarray(data.data_features.values)\n",
    "\n",
    "    ## targets\n",
    "    labels = np.asarray(data.data_targets.values)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "x_train, y_train = prepare_data_for_classification(train_data)\n",
    "x_val, y_val = prepare_data_for_classification(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers, initializers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.models import Model, Input\n",
    "from keras import optimizers\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from random import shuffle\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*do not.*',)\n",
    "\n",
    "\n",
    "\n",
    "def create_model(input_shape, output_shape):\n",
    "\n",
    "    ## sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(Dense(10, input_dim=input_shape, activation='tanh'))\n",
    "    #model.add(Dense(12, activation='relu'))\n",
    "    #model.add(Dense(3, input_dim=input_shape, activation='relu'))\n",
    "\n",
    "    # working model___________\n",
    "    #model.add(Dense(3, input_dim=input_shape, activation='relu'))\n",
    "    #model.add(Dense(12, activation='relu'))\n",
    "    #model.add(Dense(12, activation='relu'))\n",
    "\n",
    "\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(output_shape, input_dim=input_shape, activation='relu'))\n",
    "\n",
    "    ## other way of defining model\n",
    "    \n",
    "    #inputs = Input(shape=(input_shape,))\n",
    "    #outputs = Dense(output_shape, activation=\"relu\", kernel_regularizer=regularizers.l2(5e-4),kernel_initializer=initializers.he_normal(seed=13))(inputs)\n",
    "    #model = Model(inputs=inputs, outputs=outputs, name='bidder')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_curves(history):\n",
    "\n",
    "    # Loss Curves\n",
    "    plt.figure(figsize=[8, 6])\n",
    "    plt.plot(history.history['loss'], 'r', linewidth=3.0)\n",
    "    plt.plot(history.history['val_loss'], 'b', linewidth=3.0)\n",
    "    plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n",
    "    plt.xlabel('Epochs ', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.title('Loss Curves', fontsize=16)\n",
    "    plt.savefig('Results/neural_network/'  + '/loss_curve.png')\n",
    "    #plt.show()\n",
    "\n",
    "    # Accuracy Curves\n",
    "    plt.figure(figsize=[8, 6])\n",
    "    plt.plot(history.history['acc'], 'r', linewidth=3.0)\n",
    "    plt.plot(history.history['val_acc'], 'b', linewidth=3.0)\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
    "    plt.xlabel('Epochs ', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    plt.title('Accuracy Curves', fontsize=16)\n",
    "    plt.savefig('Results/neural_network/'  + '/accuracy_curve.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  22 targets:  3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_223 (Dense)            (None, 3)                 69        \n",
      "=================================================================\n",
      "Total params: 69\n",
      "Trainable params: 69\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 303925 samples, validate on 303925 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-021dac9843e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m history = model.fit(x=x_train, y=y_train, batch_size=batch_size, \n\u001b[0;32m---> 45\u001b[0;31m                     epochs=epochs, validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m# verbose=1, shuffle=True, callbacks=callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2633\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2636\u001b[0m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2587\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \"\"\"\n\u001b[1;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1425\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "output_shape = y_train.shape[1]\n",
    "\n",
    "print(\"features: \", input_shape, \"targets: \", output_shape)\n",
    "\n",
    "# Clear model, and create it\n",
    "model = create_model(input_shape, output_shape)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "## save model to disk_____________________________________\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "\n",
    "#if not os.path.exists('Results/neural_network'):\n",
    "#    os.makedirs('Results/neural_network/')\n",
    "\n",
    "#with open('Results/neural_network/' + 'model_architecture.json', \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "\n",
    "    \n",
    "\n",
    "## hyperparameters_______________________________________\n",
    "    \n",
    "\n",
    "## model compile and train\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# specify learning rate\n",
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='loss', patience=100),\n",
    "             ModelCheckpoint('Results/neural_network/' + 'trained_weights.h5', monitor='loss', save_best_only=True)]\n",
    "\n",
    "# Fit the model on the batches\n",
    "batch_size = 4\n",
    "epochs = 2\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=batch_size, \n",
    "                    epochs=epochs, validation_data=(x_val, y_val))\n",
    "# verbose=1, shuffle=True, callbacks=callbacks\n",
    "\n",
    "## model evaluate\n",
    "plot_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303925/303925 [==============================] - 6s 21us/step\n",
      "0.0    303925\n",
      "Name: click, dtype: int64\n",
      "        click  bidprice  payprice\n",
      "0         0.0  4.418545  1.229837\n",
      "1         0.0  7.026196  1.929624\n",
      "2         0.0  4.265340  1.177227\n",
      "3         0.0  4.418545  1.229837\n",
      "4         0.0  6.331016  1.811837\n",
      "5         0.0  4.480392  1.236434\n",
      "6         0.0  7.026196  1.929624\n",
      "7         0.0  5.526566  1.577196\n",
      "8         0.0  4.265340  1.177227\n",
      "9         0.0  8.523921  2.426386\n",
      "10        0.0  4.418545  1.229837\n",
      "11        0.0  4.418545  1.229837\n",
      "12        0.0  7.026196  1.929624\n",
      "13        0.0  3.527709  0.980420\n",
      "14        0.0  6.289568  1.846444\n",
      "15        0.0  8.523921  2.426386\n",
      "16        0.0  7.026196  1.929624\n",
      "17        0.0  7.026196  1.929624\n",
      "18        0.0  4.418545  1.229837\n",
      "19        0.0  4.418545  1.229837\n",
      "20        0.0  5.871641  1.654992\n",
      "21        0.0  4.418545  1.229837\n",
      "22        0.0  4.480392  1.236434\n",
      "23        0.0  4.418545  1.229837\n",
      "24        0.0  4.265340  1.177227\n",
      "25        0.0  5.649624  1.576489\n",
      "26        0.0  8.523921  2.426386\n",
      "27        0.0  7.032995  2.105220\n",
      "28        0.0  4.418545  1.229837\n",
      "29        0.0  4.418545  1.229837\n",
      "...       ...       ...       ...\n",
      "303895    0.0  4.418545  1.229837\n",
      "303896    0.0  7.026196  1.929624\n",
      "303897    0.0  8.523921  2.426386\n",
      "303898    0.0  7.026196  1.929624\n",
      "303899    0.0  8.523921  2.426386\n",
      "303900    0.0  4.265340  1.177227\n",
      "303901    0.0  8.523921  2.426386\n",
      "303902    0.0  4.418545  1.229837\n",
      "303903    0.0  5.871641  1.654992\n",
      "303904    0.0  7.026196  1.929624\n",
      "303905    0.0  4.418545  1.229837\n",
      "303906    0.0  8.523921  2.426386\n",
      "303907    0.0  7.202217  1.994761\n",
      "303908    0.0  3.124621  0.848070\n",
      "303909    0.0  7.026196  1.929624\n",
      "303910    0.0  8.523921  2.426386\n",
      "303911    0.0  7.026196  1.929624\n",
      "303912    0.0  4.265340  1.177227\n",
      "303913    0.0  8.523921  2.426386\n",
      "303914    0.0  4.418545  1.229837\n",
      "303915    0.0  8.523921  2.426386\n",
      "303916    0.0  7.026196  1.929624\n",
      "303917    0.0  5.871641  1.654992\n",
      "303918    0.0  7.026196  1.929624\n",
      "303919    0.0  8.523921  2.426386\n",
      "303920    0.0  6.289568  1.846444\n",
      "303921    0.0  4.265340  1.177227\n",
      "303922    0.0  3.527709  0.980420\n",
      "303923    0.0  4.418545  1.229837\n",
      "303924    0.0  7.026196  1.929624\n",
      "\n",
      "[303925 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "## Load Model for Testing_______________________________________________________________\n",
    "\n",
    "# Model reconstruction from JSON file\n",
    "#with open('Results/neural_network/' + 'model_architecture.json', 'r') as f:\n",
    "#    model_test = model_from_json(f.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "#model_test.load_weights('Results/neural_network/' + 'trained_weights.h5')\n",
    "\n",
    "#model_test.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "predictions = model.predict(x_val, verbose=1)\n",
    "predictions_df = pd.DataFrame(predictions, columns= ['click', 'bidprice', 'payprice'])\n",
    "\n",
    "print(predictions_df['click'].value_counts())\n",
    "print(predictions_df)\n",
    "\n",
    "#test_score = model.evaluate(x = x_val, y = y_val)\n",
    "#print('\\ntest accuracy:', test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
