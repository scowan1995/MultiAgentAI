{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from Preprocessing import preprocessing\n",
    "from Preprocessing.single_set import SingleSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Features: data.data_features\n",
    "Targets: data.data_targets (click, bidprice, payprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- data loaded --\n",
      "-- data loaded --\n",
      "-- data loaded --\n"
     ]
    }
   ],
   "source": [
    "train_data_path = '/Data/train.csv'\n",
    "train_data = SingleSet(relative_path=train_data_path,use_numerical_labels=True)\n",
    "\n",
    "val_data_path = '/Data/validation.csv'\n",
    "val_data = SingleSet(relative_path=val_data_path,use_numerical_labels=True)\n",
    "\n",
    "test_data_path = '/Data/test.csv'\n",
    "test_data = SingleSet(relative_path=test_data_path,use_numerical_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_numpy(data):\n",
    "\n",
    "    ## features\n",
    "    features = np.asarray(data.data_features.values)\n",
    "\n",
    "    ## targets\n",
    "    if hasattr(data, \"data_targets\"):\n",
    "        labels = np.asarray(data.data_targets.values)\n",
    "        \n",
    "    return features, labels\n",
    "\n",
    "\n",
    "## drop unnecessary features\n",
    "def drop_features(data):\n",
    "    \n",
    "    keep_features = [\"hour\", \"useragent\", \"adexchange\", \"url\", \"slotformat\", \"slotid\"]\n",
    "    for f in data.data_features:\n",
    "        if f not in keep_features:\n",
    "            data.data_features.drop(f, axis=1, inplace = True)\n",
    "    \n",
    "    \n",
    "train_data_click = copy.deepcopy(train_data)\n",
    "val_data_click = copy.deepcopy(val_data)\n",
    "test_data_click = copy.deepcopy(test_data)\n",
    "\n",
    "drop_features(train_data_click)\n",
    "drop_features(val_data_click)\n",
    "drop_features(test_data_click)\n",
    "\n",
    "x_train_clicks, y_train = pandas_to_numpy(train_data_click)\n",
    "x_val_clicks, y_val = pandas_to_numpy(val_data_click)\n",
    "x_test_clicks, y_test = pandas_to_numpy(test_data_click)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape 6\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train_clicks.shape[1]\n",
    "print(\"input_shape\", input_shape)\n",
    "output_shape = 1\n",
    "\n",
    "# targets_________________________________________________\n",
    "\n",
    "# clicks\n",
    "y_train_clicks = np.reshape(y_train[:,0], (y_train.shape[0], 1))  # get first column (clicks)\n",
    "y_val_clicks = np.reshape(y_val[:,0], (y_val.shape[0], 1))  # get first column (clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(x_train, x_val, x_test):\n",
    "    \n",
    "    # normalize the data attributes\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    #normalized_X = preprocessing.normalize(x_train)\n",
    "\n",
    "\n",
    "\n",
    "    ## features\n",
    "    feature_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    feature_scaler.fit(np.concatenate((x_train, x_val, x_test), axis = 0))       \n",
    "\n",
    "    x_train = feature_scaler.transform(x_train)\n",
    "    x_val = feature_scaler.transform(x_val)\n",
    "    x_test = feature_scaler.transform(x_test)\n",
    "    \n",
    "    return x_train, x_val, x_test\n",
    "\n",
    "    ## Targets________________________________________\n",
    "\n",
    "    # payprice\n",
    "    #payprice_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    #payprice_scaler.fit(np.concatenate((y_train_payprice, y_val_payprice), axis = 0))   \n",
    "\n",
    "    #y_train_payprice = payprice_scaler.transform(y_train_payprice)\n",
    "    #y_val_payprice = payprice_scaler.transform(y_val_payprice)\n",
    "\n",
    "#x_train, x_val, x_test = scale_data(x_train, x_val, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Neural Networks\n",
    "\n",
    "## \"Click\" - Binary Classification\n",
    "\n",
    "Train Baseline Accuracy \"Clicks\": 0.9992618932746251%\n",
    "#of 0:    2429188     # of 1:       1793\n",
    "\n",
    "\n",
    "Val Baseline Accuracy \"Clicks\": 0.9993349203056733%\n",
    "#of 0:    303723     # of 1:       202\n",
    "\n",
    "Average CTR:\n",
    "\n",
    "1793 / 2429188 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling\n",
    "\n",
    "sample up \"1\"s for more balanced classification\n",
    "\n",
    "--> default accuracy: 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling(x, y):\n",
    "\n",
    "    xy = np.concatenate((x, y), axis = 1)\n",
    "\n",
    "    zeros = xy[xy[:,-1] == 0]\n",
    "    ones = xy[xy[:,-1] == 1]\n",
    "\n",
    "    ones_upsampled = np.repeat(ones, math.ceil(len(zeros)/len(ones)), axis=0)\n",
    "\n",
    "    # cut at length of zeros.shape 2429188\n",
    "    ones_upsampled = ones_upsampled[:zeros.shape[0]]\n",
    "\n",
    "    xy_upsampled  = np.concatenate((ones_upsampled, zeros), axis = 0) # combine\n",
    "    np.random.shuffle(xy_upsampled)                                   # shuffle\n",
    "\n",
    "    x_upsampled = xy_upsampled[:,:-1]   # features\n",
    "    y_upsampled = xy_upsampled[:,-1:]   # targets\n",
    "    \n",
    "    return x_upsampled, y_upsampled\n",
    "\n",
    "\n",
    "#x_train_up, y_train_clicks_up = upsampling(x_train, y_train_clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer / Categorical One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_clicks_up = keras.utils.to_categorical(y_train_clicks_up, 2)\n",
    "#y_val_clicks = keras.utils.to_categorical(y_val_clicks, 2)\n",
    "\n",
    "#y_train_clicks_up = y_train_clicks_up.astype(int)\n",
    "#y_val_clicks = y_val_clicks.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - \"Clicks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Index(['hour', 'useragent', 'adexchange', 'url', 'slotid', 'slotformat'], dtype='object')\n",
      "[[-1.59960239e-01 -1.44829606e-01 -5.76878715e-03 -1.29796495e-06\n",
      "  -2.85439513e-05  1.03332108e-03]]\n",
      "\n",
      "-- logistic regression completed --\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class_weight = {0: 0.5, 1: 0.5}#{0: (1793 / 2429188), 1: (1-(1793 / 2429188))}#{0: 0.5, 1: 0.5}\n",
    "\n",
    "log_regression = LogisticRegression(class_weight=class_weight,  C=1.0, penalty = 'l2', verbose=10).fit(x_train_clicks, y_train_clicks)\n",
    "## model coefficients\n",
    "print(train_data_click.data_features.columns)\n",
    "print(log_regression.coef_)\n",
    "\n",
    "print(\"\\n-- logistic regression completed --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    303925\n",
      "Name: click, dtype: int64\n",
      "Accuracy of logistic regression classifier on test set: 1.00\n",
      "\n",
      "F1_score: 0.9990031539865409\n",
      "Accuracy: 0.9993353623426833 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# USE PREDICTION DIRECTLY________________________________________\n",
    "\n",
    "def click_prediction(log_regression, features, labels = None):\n",
    "\n",
    "    click_predictions = log_regression.predict(features)\n",
    "    click_predictions_df = pd.DataFrame(click_predictions, columns= ['click'])\n",
    "    print(click_predictions_df['click'].value_counts())\n",
    "\n",
    "\n",
    "    if labels is not None:\n",
    "        \n",
    "        print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(log_regression.score(features, labels)))\n",
    "\n",
    "        from sklearn import metrics\n",
    "        print(\"\\nF1_score:\", metrics.f1_score(labels, click_predictions, average='weighted'))\n",
    "        print(\"Accuracy:\", metrics.accuracy_score(labels, click_predictions), \"\\n\")\n",
    "\n",
    "    return click_predictions\n",
    "\n",
    "\n",
    "\n",
    "# USE PREDICTION PROBABILITY________________________________________\n",
    "\n",
    "def click_prob_prediction(log_regression, click_thres_prob, return_binary, features, labels = None):\n",
    "\n",
    "    \n",
    "    click_predictions_prob = log_regression.predict_proba(features)\n",
    "\n",
    "    \n",
    "    if return_binary == False:\n",
    "        \n",
    "        return click_predictions_prob\n",
    "    \n",
    "    if return_binary == True:\n",
    "\n",
    "        click_prob_decision = list()\n",
    "\n",
    "        for pred in click_predictions_prob:\n",
    "            if pred[1] > click_thres_prob:\n",
    "                click_prob_decision.append(int(1.0))\n",
    "            else:\n",
    "                click_prob_decision.append(int(0.0))\n",
    "\n",
    "        click_predictions_prob_df = pd.DataFrame(click_prob_decision, columns= ['click'])\n",
    "        print(click_predictions_prob_df['click'].value_counts())\n",
    "\n",
    "        if labels is not None:\n",
    "\n",
    "            from sklearn import metrics\n",
    "            print(\"\\nF1_score:\", metrics.f1_score(labels, click_prob_decision, average='weighted'))\n",
    "            print(\"Accuracy:\", metrics.accuracy_score(labels, click_prob_decision), \"\\n\")\n",
    "\n",
    "        return click_prob_decision \n",
    "\n",
    "\n",
    "\n",
    "click_thres_prob = 0.5\n",
    "return_binary = False\n",
    "\n",
    "click_predictions = click_prediction(log_regression, x_val_clicks, y_val_clicks)\n",
    "#click_predictions = click_prob_prediction(log_regression, click_thres_prob, return_binary, x_val, y_val_clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - \"Payprice\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape 6\n"
     ]
    }
   ],
   "source": [
    "train_data_payprice = copy.deepcopy(train_data)\n",
    "val_data_payprice = copy.deepcopy(val_data)\n",
    "test_data_payprice = copy.deepcopy(test_data)\n",
    "\n",
    "\n",
    "def pandas_to_numpy(data):\n",
    "\n",
    "    ## features\n",
    "    features = np.asarray(data.data_features.values)\n",
    "\n",
    "    ## targets\n",
    "    if hasattr(data, \"data_targets\"):\n",
    "        labels = np.asarray(data.data_targets.values)\n",
    "        \n",
    "    return features, labels\n",
    "\n",
    "\n",
    "## drop unnecessary features\n",
    "def drop_features(data):\n",
    "    \n",
    "    keep_features = [\"adexchange\", \"domain\", \"slotwidth\", \"slotheight\", \"slotformat\", \"slotprice\"]\n",
    "    for f in data.data_features:\n",
    "        if f not in keep_features:\n",
    "            data.data_features.drop(f, axis=1, inplace = True)\n",
    "    \n",
    "\n",
    "drop_features(train_data_payprice)\n",
    "drop_features(val_data_payprice)\n",
    "drop_features(test_data_payprice)\n",
    "\n",
    "x_train_payprice, y_train = pandas_to_numpy(train_data_payprice)\n",
    "x_val_payprice, y_val = pandas_to_numpy(val_data_payprice)\n",
    "x_test_payprice, y_test = pandas_to_numpy(test_data_payprice)\n",
    "\n",
    "\n",
    "input_shape = x_train_payprice.shape[1]\n",
    "print(\"input_shape\", input_shape)\n",
    "output_shape = 1\n",
    "\n",
    "# payprice\n",
    "y_train_payprice = np.reshape(y_train[:,2], (y_train.shape[0], 1))  # get third column (payprice)\n",
    "y_val_payprice = np.reshape(y_val[:,2], (y_val.shape[0], 1))  # get third column (payprice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['adexchange', 'domain', 'slotwidth', 'slotheight', 'slotformat',\n",
      "       'slotprice'],\n",
      "      dtype='object')\n",
      "[[-9.49636406e+00  9.49156433e-04 -1.99829419e-02 -1.34565218e-02\n",
      "   1.29929560e+01  5.63191752e-01]]\n",
      "\n",
      "-- linear regression completed --\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_regression = LinearRegression(normalize = True).fit(x_train_payprice, y_train_payprice)\n",
    "\n",
    "## model coefficients\n",
    "print(train_data_payprice.data_features.columns)\n",
    "print(lin_regression.coef_)\n",
    "\n",
    "print(\"\\n-- linear regression completed --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.11\n",
      "\n",
      "Mean Squared Error: 3215.034565779497 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USE PREDICTION DIRECTLY________________________________________\n",
    "\n",
    "def payprice_prediction(lin_regression, features, labels = None):\n",
    "\n",
    "    payprice_predictions = lin_regression.predict(x_val_payprice)\n",
    "    payprice_predictions_df = pd.DataFrame(payprice_predictions, columns= ['payprice'])\n",
    "    #print(payprice_predictions_df)\n",
    "    \n",
    "    if labels is not None:\n",
    "        \n",
    "        print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(lin_regression.score(features, labels)))\n",
    "\n",
    "        from sklearn import metrics\n",
    "        print(\"\\nMean Squared Error:\", metrics.mean_squared_error(labels, payprice_predictions), \"\\n\")\n",
    "\n",
    "    return payprice_predictions\n",
    "\n",
    "payprice_predictions = payprice_prediction(lin_regression, x_val_payprice, y_val_payprice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Bidding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Clicks and Payprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click prediction\n",
      "payprice prediction\n",
      "Accuracy of logistic regression classifier on test set: 0.11\n",
      "\n",
      "Mean Squared Error: 3215.034565779497 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pick_data = \"val\"\n",
    "\n",
    "\n",
    "def predict_clicks_payprice(click_thres_prob, return_binary):\n",
    "\n",
    "    # VAL______________\n",
    "\n",
    "    if pick_data == \"val\":\n",
    "\n",
    "        ## CLICKS___________\n",
    "\n",
    "        #y_val_clicks\n",
    "\n",
    "        print(\"click prediction\")\n",
    "        #click_predictions = click_prediction(log_regression, x_val, y_val_clicks)\n",
    "        click_predictions = click_prob_prediction(log_regression, click_thres_prob, return_binary, x_val_clicks, y_val_clicks)\n",
    "\n",
    "        ## PAYPRICE___________\n",
    "\n",
    "        #y_val_payprice\n",
    "        print(\"payprice prediction\")\n",
    "        payprice_predictions = payprice_prediction(lin_regression, x_val_payprice, y_val_payprice)\n",
    "\n",
    "\n",
    "\n",
    "    # TEST______________\n",
    "\n",
    "    if pick_data == \"test\": \n",
    "\n",
    "\n",
    "        ## CLICKS___________\n",
    "\n",
    "        #y_val_clicks\n",
    "\n",
    "        print(\"click prediction\")\n",
    "        #click_predictions = click_prediction(log_regression, x_test)\n",
    "        click_predictions = click_prob_prediction(log_regression, click_thres_prob, return_binary, x_test)\n",
    "\n",
    "        ## PAYPRICE___________\n",
    "\n",
    "        #y_val_payprice\n",
    "\n",
    "        print(\"payprice prediction\")\n",
    "        payprice_predictions = payprice_prediction(lin_regression, x_test)\n",
    "        \n",
    "    return click_predictions, payprice_predictions\n",
    "\n",
    "\n",
    "click_predictions, payprice_predictions = predict_clicks_payprice(click_thres_prob = 0.5, return_binary = False)\n",
    "\n",
    "#print(payprice_predictions[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Bidding Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bids(click_predictions, payprice_predictions, base_bid, averageCTR, click_predict_weight = None):\n",
    "    \n",
    "    budget = 6250000\n",
    "    bids = np.zeros((len(click_predictions)))\n",
    "\n",
    "## 1.) Only bid for expected clicks!\n",
    "\n",
    "    predicted_clicks = 0\n",
    "    spend_on_clicks = 0\n",
    "    \n",
    "    for p in range(0, len(bids)):\n",
    "\n",
    "        #if click_predictions[p] == 1:\n",
    "            \n",
    "        predicted_clicks += 1\n",
    "\n",
    "        bid_price = base_bid * click_predictions[p,1] / np.mean(click_predictions[:,1]) #+ click_predict_weight * (click_predictions[p][1]) #/ averageCTR\n",
    "        #bid_price = math.floor(payprice_predictions[p]) + 2 #np.random.randint(10,10)\n",
    "        #bid_price = 72\n",
    "        spend_on_clicks += bid_price\n",
    "\n",
    "        bids[p] = bid_price\n",
    "        #bids[p] = 71\n",
    "            \n",
    "    print(\"\\npredicted_clicks:\", predicted_clicks)\n",
    "    print(\"spent_on_clicks:\", spend_on_clicks)\n",
    "    print(\"average_spent:\", spend_on_clicks / predicted_clicks, \"\\n\")\n",
    "    \n",
    "    return bids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adjust_bidprices(bids, payprice_predictions):\n",
    "    \n",
    "    ## 2.) Prefer cheap payprice predictions\n",
    "    \n",
    "    budget = 6250000\n",
    "    planned_bid_amount = sum(bids)\n",
    "    exceed_budget = 1000\n",
    "    n_bids = len(bids[np.where(bids > 0)])\n",
    "\n",
    "    \n",
    "    ## (1) spend too much_______________________\n",
    "    \n",
    "    if planned_bid_amount - budget > 0:\n",
    "        \n",
    "        print(\"-- spend too much:\", planned_bid_amount - budget)\n",
    "        \n",
    "        while (planned_bid_amount - budget > exceed_budget):\n",
    "\n",
    "            #print(round(np.mean(bids)))\n",
    "            #print(budget - planned_bid_amount)\n",
    "            index, = list(np.where(bids == max(bids)))    # find expensive bids\n",
    "            bids[index] = max(bids) - 1                   # set expensive bid lower\n",
    "            planned_bid_amount = sum(bids)                # check new bidding amount\n",
    "\n",
    "    \n",
    "    ## (2) spend too little______________________\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(\"-- spend too little:\", budget - planned_bid_amount)\n",
    "        \n",
    "        #fill_bid_price = math.floor(np.mean(bids))\n",
    "        fill_bid_price = 70\n",
    "        \n",
    "        while (budget - planned_bid_amount >  (-exceed_budget)):\n",
    "\n",
    "            #print(round(np.mean(bids)))\n",
    "            #print(budget - planned_bid_amount)\n",
    "            index, = list(np.where(bids == 0)) \n",
    "            index = random.sample(list(index), 100)\n",
    "            bids[index] = fill_bid_price            \n",
    "            planned_bid_amount = sum(bids)                \n",
    "\n",
    "\n",
    "    n_bids = len(bids[np.where(bids > 0)])  \n",
    "    print(\"\\nplanned_bid_amount:\", sum(bids), \", difference to budget:\", (budget - sum(bids)), \n",
    "              \", number of bids:\", n_bids, \", average bidprice:\",round(np.mean(bids[np.where(bids > 0)])))\n",
    "    \n",
    "    return bids\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predicted_clicks: 303925\n",
      "spent_on_clicks: 21274750.00000019\n",
      "average_spent: 70.00000000000063 \n",
      "\n",
      "-- spend too much: 15024750.00000019\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-35bd6e36bbec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbid_decisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_bids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclick_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayprice_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_bid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverageCTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjust_bidprices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbid_decisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayprice_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-3e9adf80a8db>\u001b[0m in \u001b[0;36madjust_bidprices\u001b[0;34m(bids, payprice_predictions)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbids\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# find expensive bids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mbids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m                   \u001b[0;31m# set expensive bid lower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mplanned_bid_amount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbids\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# check new bidding amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_bid = 70\n",
    "averageCTR = 1793 / 2429188 \n",
    "\n",
    "bid_decisions = set_bids(click_predictions, payprice_predictions, base_bid, averageCTR)\n",
    "bids = adjust_bidprices(bid_decisions, payprice_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Decision in Auction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath(os.pardir + '/Data/validation.csv')\n",
    "df = pd.read_csv(data_path, na_values=['Na', 'null']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-3f1adfb758d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0msimulate_auction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bids' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def simulate_auction(bids):\n",
    "\n",
    "    if pick_data == \"val\": \n",
    "\n",
    "        budget = 6250000\n",
    "\n",
    "        ## Evaluation Stats_____________\n",
    "\n",
    "        bids_won = 0\n",
    "        earned_clicks = 0\n",
    "        ctr = 0                  # bids_won / earned_clicks\n",
    "        total_paid = 0\n",
    "        cpc = 0                  # cost per click\n",
    "\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            if bids[index] > budget: # check if budget is sufficient for bidprice\n",
    "                bids[index] = budget\n",
    "                #print(\"constant bid reduced to:\", constant_bid, \", total_paid:\", total_paid, \", bids_won:\", bids_won, \", earned clicks:\", earned_clicks, \"\\n\")\n",
    "\n",
    "            if budget <= 0:\n",
    "                print(\"-- break after auction #\", index)\n",
    "                break\n",
    "\n",
    "            # WON BID ______________________________________________\n",
    "\n",
    "            if bids[index] >= row['payprice']:     \n",
    "\n",
    "                bids_won += 1                        # won the bid\n",
    "                total_paid += row['payprice']        # add amount to total_paid   \n",
    "                budget = budget - row['payprice']    # substract money from budget\n",
    "\n",
    "                #if constant_bid == row['bidprice']:      \n",
    "                    #budget = budget - row['payprice']    # substract money from budget\n",
    "\n",
    "                #elif constant_bid > row['bidprice']:\n",
    "                #    budget = budget - row['bidprice']    # substract money from budget\n",
    "\n",
    "                # CLICK = 1 ______________________________________________\n",
    "\n",
    "                if row['click'] == 1:    # only reduce money from budget if ad has been clicked\n",
    "\n",
    "                        earned_clicks += 1                   # earn the click\n",
    "                        #print(\"current budget:\", budget, \", earned clicks:\", earned_clicks, \"\\n\")\n",
    "\n",
    "            if index%100000 == 0:\n",
    "                print(\"bid#\", index, \", budget:\", budget, \", payprice:\", row['payprice'], \", bids_won:\", bids_won, \", earned_clicks:\", earned_clicks, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        print(\"__________________________________\\n\")\n",
    "\n",
    "        if earned_clicks > 0:\n",
    "            cpc = total_paid / earned_clicks\n",
    "        if bids_won > 0:\n",
    "            ctr = earned_clicks / bids_won\n",
    "\n",
    "        print(\"left budget:\", budget)\n",
    "        print(\"bids_won:\", bids_won)\n",
    "        print(\"earned clicks:\", earned_clicks)\n",
    "        print(\"CTR:\", ctr)\n",
    "        print(\"cost per click:\", cpc)\n",
    "\n",
    "        \n",
    "simulate_auction(bids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_________________________________________\n",
      "\n",
      "PARAMETER: base_bid 70\n",
      "click prediction\n",
      "payprice prediction\n",
      "Accuracy of logistic regression classifier on test set: 0.11\n",
      "\n",
      "Mean Squared Error: 3215.034565779497 \n",
      "\n",
      "\n",
      "predicted_clicks: 303925\n",
      "spent_on_clicks: 21274750.00000019\n",
      "average_spent: 70.00000000000063 \n",
      "\n",
      "bid# 0 , budget: 6249977 , payprice: 23 , bids_won: 1 , earned_clicks: 0 \n",
      "\n",
      "bid# 100000 , budget: 4141027 , payprice: 63 , bids_won: 54977 , earned_clicks: 26 \n",
      "\n",
      "bid# 200000 , budget: 2024727 , payprice: 196 , bids_won: 110128 , earned_clicks: 52 \n",
      "\n",
      "-- break after auction # 297159\n",
      "__________________________________\n",
      "\n",
      "left budget: 0\n",
      "bids_won: 162883\n",
      "earned clicks: 76\n",
      "CTR: 0.0004665925848615264\n",
      "cost per click: 82236.84210526316\n",
      "_________________________________________\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averageCTR = 1793 / 2429188 \n",
    "\n",
    "#for click_thres_prob in [0.8]:\n",
    "for base_bid in [70]:\n",
    "    #for click_predict_weight in [120.5]:\n",
    "\n",
    "    print(\"\\n\\n\\n_________________________________________\\n\")\n",
    "    print(\"PARAMETER: base_bid\", base_bid)#, \"click_predict_weight\", click_predict_weight, \"click_thres_prob\", click_thres_prob,\"\\n\")\n",
    "\n",
    "    click_predictions, payprice_predictions = predict_clicks_payprice(click_thres_prob, return_binary = False)\n",
    "    bid_decisions = set_bids(click_predictions, payprice_predictions, base_bid, averageCTR)\n",
    "    #bids = adjust_bidprices(bid_decisions, budget, payprice_predictions)\n",
    "    simulate_auction(bid_decisions)\n",
    "\n",
    "    print(\"_________________________________________\\n\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_test = os.path.abspath(os.pardir + '/Data/test.csv')\n",
    "df_test = pd.read_csv(data_path_test, na_values=['Na', 'null']).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidprice_series = pd.Series(data = bids, name='bidprice')\n",
    "submission_df = pd.DataFrame({'bidid': df_test['bidid'],'bidprice':bidprice_series})\n",
    "\n",
    "# Group Token: QQri5ISZz4Kn\n",
    "submission_df.to_csv('testing_bidding_price.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load old Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidprice_series = pd.Series(data = df_test_adjusted, name='bidprice')\n",
    "submission_df = pd.DataFrame({'bidid': df_test['bidid'],'bidprice':bidprice_series})\n",
    "\n",
    "# Group Token: QQri5ISZz4Kn\n",
    "submission_df.to_csv('testing_bidding_price.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bidid', 'bidprice'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_test_final = pd.read_csv(\"/Users/niklasstoehr/Desktop/criterion_1_test_results.csv\")\n",
    "print(df_test_final.columns)\n",
    "df_test_final = df_test_final.bidprice.astype(int)\n",
    "\n",
    "sum(df_test_final)\n",
    "df_test_adjusted = df_test_final.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22775651\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "df_test_adjusted = np.clip(df_test_adjusted, 0, 305)\n",
    "print(sum(df_test_adjusted))\n",
    "df_test_adjusted[0] = 100\n",
    "print(df_test_adjusted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004853689726435591\n",
      "1.001091978400976\n",
      "[0.99212988 1.13713592 0.98328965 ... 1.03972609 1.07281731 0.99377936]\n"
     ]
    }
   ],
   "source": [
    "test_probs = click_prob_prediction(log_regression, click_thres_prob, return_binary, x_test_clicks)\n",
    "one_prob = test_probs[:,1]\n",
    "print(np.mean(one_prob))\n",
    "one_prob = (one_prob + (1 - np.mean(one_prob)))**4\n",
    "\n",
    "print(np.mean(one_prob))\n",
    "print(one_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         100\n",
      "1         305\n",
      "2          61\n",
      "3          43\n",
      "4          71\n",
      "5          63\n",
      "6          56\n",
      "7          87\n",
      "8          56\n",
      "9          26\n",
      "10         52\n",
      "11        305\n",
      "12         72\n",
      "13         77\n",
      "14         57\n",
      "15        305\n",
      "16         29\n",
      "17         86\n",
      "18         28\n",
      "19         43\n",
      "20         28\n",
      "21         87\n",
      "22         35\n",
      "23         39\n",
      "24         48\n",
      "25        196\n",
      "26         90\n",
      "27         43\n",
      "28         61\n",
      "29         72\n",
      "         ... \n",
      "303345     44\n",
      "303346     33\n",
      "303347     59\n",
      "303348    122\n",
      "303349     71\n",
      "303350     55\n",
      "303351     81\n",
      "303352    103\n",
      "303353     74\n",
      "303354     78\n",
      "303355     84\n",
      "303356     67\n",
      "303357    305\n",
      "303358     60\n",
      "303359     50\n",
      "303360     75\n",
      "303361    125\n",
      "303362     63\n",
      "303363     65\n",
      "303364     56\n",
      "303365     59\n",
      "303366    109\n",
      "303367     72\n",
      "303368    305\n",
      "303369     11\n",
      "303370     17\n",
      "303371     63\n",
      "303372     92\n",
      "303373     49\n",
      "303374     44\n",
      "Name: bidprice, Length: 303375, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.07424474660074"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test_adjusted )\n",
    "np.mean(df_test_adjusted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          99.212988\n",
      "1         346.826456\n",
      "2          59.980669\n",
      "3          42.284912\n",
      "4          69.798472\n",
      "5          61.957732\n",
      "6          55.275543\n",
      "7          90.151684\n",
      "8          55.810122\n",
      "9          25.917824\n",
      "10         51.339292\n",
      "11        322.318494\n",
      "12         74.444515\n",
      "13         75.646271\n",
      "14         56.001182\n",
      "15        300.337153\n",
      "16         28.775104\n",
      "17         85.208866\n",
      "18         27.577602\n",
      "19         43.258762\n",
      "20         27.706380\n",
      "21         85.536434\n",
      "22         34.808632\n",
      "23         38.518641\n",
      "24         47.170851\n",
      "25        194.701078\n",
      "26         89.279180\n",
      "27         42.337457\n",
      "28         60.006444\n",
      "29         71.436100\n",
      "             ...    \n",
      "303345     43.251106\n",
      "303346     32.463304\n",
      "303347     58.045265\n",
      "303348    120.093527\n",
      "303349     73.267431\n",
      "303350     54.025795\n",
      "303351     79.666543\n",
      "303352    101.686457\n",
      "303353     73.502528\n",
      "303354     76.639009\n",
      "303355     83.147292\n",
      "303356     66.627956\n",
      "303357    300.501087\n",
      "303358     59.035093\n",
      "303359     50.112451\n",
      "303360     73.713779\n",
      "303361    122.954391\n",
      "303362     62.773028\n",
      "303363     64.068581\n",
      "303364     55.401863\n",
      "303365     58.300355\n",
      "303366    107.972471\n",
      "303367     71.856225\n",
      "303368    299.873998\n",
      "303369     10.811223\n",
      "303370     16.709318\n",
      "303371     62.404260\n",
      "303372     95.654800\n",
      "303373     52.568048\n",
      "303374     43.726292\n",
      "Name: bidprice, Length: 303375, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_test_adjusted * one_prob)\n",
    "\n",
    "df_test_adjusted = df_test_adjusted * one_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          99\n",
      "1         346\n",
      "2          59\n",
      "3          42\n",
      "4          69\n",
      "5          61\n",
      "6          55\n",
      "7          90\n",
      "8          55\n",
      "9          25\n",
      "10         51\n",
      "11        322\n",
      "12         74\n",
      "13         75\n",
      "14         56\n",
      "15        300\n",
      "16         28\n",
      "17         85\n",
      "18         27\n",
      "19         43\n",
      "20         27\n",
      "21         85\n",
      "22         34\n",
      "23         38\n",
      "24         47\n",
      "25        194\n",
      "26         89\n",
      "27         42\n",
      "28         60\n",
      "29         71\n",
      "         ... \n",
      "303345     43\n",
      "303346     32\n",
      "303347     58\n",
      "303348    120\n",
      "303349     73\n",
      "303350     54\n",
      "303351     79\n",
      "303352    101\n",
      "303353     73\n",
      "303354     76\n",
      "303355     83\n",
      "303356     66\n",
      "303357    300\n",
      "303358     59\n",
      "303359     50\n",
      "303360     73\n",
      "303361    122\n",
      "303362     62\n",
      "303363     64\n",
      "303364     55\n",
      "303365     58\n",
      "303366    107\n",
      "303367     71\n",
      "303368    299\n",
      "303369     10\n",
      "303370     16\n",
      "303371     62\n",
      "303372     95\n",
      "303373     52\n",
      "303374     43\n",
      "Name: bidprice, Length: 303375, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.89555500618047"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test_adjusted.astype(int))\n",
    "df_test_adjusted = df_test_adjusted.astype(int)\n",
    "np.mean(df_test_adjusted)\n",
    "#df_test_adjusted = (df_test_adjusted * one_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
